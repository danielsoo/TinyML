{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  TinyML - Colab Training Notebook\n",
    "\n",
    "This notebook trains your TinyML model on Google Colab GPU.\n",
    "\n",
    "**Flow:**\n",
    "1. Check GPU\n",
    "2. Clone or update your GitHub repo\n",
    "3. Install Colab-compatible dependencies\n",
    "4. Run training script (`train.py` or `src/train.py`)\n",
    "5. Save exported model (e.g. `tiny_model.tflite`) to Google Drive\n",
    "\n",
    "Customize the training script path in the **Run training** cell if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ê²°\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. ë°ì´í„° í´ë” ê²½ë¡œ ì„¤ì •\n",
    "DATA_DIR = \"/content/drive/MyDrive/TinyML_models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Runtime & GPU check\n",
    "Make sure you set **Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU** before running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi || echo \"No NVIDIA GPU detected. Please enable GPU in Runtime settings.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Clone or update TinyML repository\n",
    "\n",
    "Set your GitHub repo URL if different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = \"https://github.com/danielsoo/TinyML.git\"  # change if needed\n",
    "PROJECT_DIR = \"/content/TinyML\"\n",
    "\n",
    "if not os.path.exists(PROJECT_DIR):\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, PROJECT_DIR], check=True)\n",
    "else:\n",
    "    subprocess.run([\"git\", \"-C\", PROJECT_DIR, \"pull\"], check=True)\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "subprocess.run([\"ls\"], check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4756a1",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£.5 Update config data path\n",
    "Google Driveì— ìžˆëŠ” ë°ì´í„° ê²½ë¡œ(`DATA_DIR`)ë¥¼ `config/federated.yaml`ì— ë°˜ì˜í•©ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231529f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "config_path = Path(PROJECT_DIR) / \"config\" / \"federated.yaml\"\n",
    "\n",
    "if config_path.exists():\n",
    "    with config_path.open(\"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    cfg.setdefault(\"data\", {})\n",
    "    cfg[\"data\"][\"path\"] = DATA_DIR\n",
    "\n",
    "    with config_path.open(\"w\") as f:\n",
    "        yaml.safe_dump(cfg, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "    print(f\"Updated federated.yaml data.path -> {cfg['data']['path']}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Cannot find {config_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Generate Colab-specific requirements (no macOS-only packages)\n",
    "\n",
    "We remove `tensorflow-macos` and `tensorflow-metal` from `requirements.txt` automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "src_req = \"requirements.txt\"\n",
    "colab_req = \"colab_requirements.txt\"\n",
    "\n",
    "# Skip packages that are preinstalled or incompatible on Colab (tensorflow/numpy variants)\n",
    "skip_keywords = [\"tensorflow\", \"numpy\", \"tensorflow-macos\", \"tensorflow-metal\"]\n",
    "\n",
    "if os.path.exists(src_req):\n",
    "    with open(src_req, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with open(colab_req, \"w\") as f:\n",
    "        for line in lines:\n",
    "            if any(kw in line for kw in skip_keywords):\n",
    "                continue\n",
    "            f.write(line)\n",
    "\n",
    "    print(\"Generated:\", colab_req)\n",
    "    with open(colab_req, \"r\") as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"No requirements.txt found. Skipping Colab requirements generation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Install dependencies (Colab compatible)\n",
    "\n",
    "- Installs from `colab_requirements.txt` if present.\n",
    "- Installs standard `tensorflow` for Linux GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(\"colab_requirements.txt\"):\n",
    "    subprocess.run([\"pip\", \"install\", \"-r\", \"colab_requirements.txt\"], check=True)\n",
    "else:\n",
    "    print(\"colab_requirements.txt not found. Install your packages manually if needed.\")\n",
    "\n",
    "subprocess.run([\"pip\", \"install\", \"flwr[simulation]\"], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ (Optional) Download or prepare dataset\n",
    "\n",
    "Edit this cell if your training script expects data in a specific path.\n",
    "For example, you can mount Google Drive or download from Kaggle here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: mount Google Drive if your data is stored there.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Example: create a data directory\n",
    "# os.makedirs('data', exist_ok=True)\n",
    "# Then copy or download your dataset into ./data\n",
    "\n",
    "print(\"Dataset preparation step: customize as needed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Run training\n",
    "\n",
    "This cell tries to run `train.py` at repo root.\n",
    "If your main script is at a different path, edit accordingly (e.g. `src/train.py`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe73708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"/content/drive/MyDrive/TinyML_models\")  # CSVë“¤ì´ ìžˆëŠ” ê²½ë¡œë¡œ ìˆ˜ì •\n",
    "csv_paths = sorted(data_dir.glob(\"*.csv\"))\n",
    "\n",
    "dfs = [pd.read_csv(p, low_memory=False) for p in csv_paths]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Total Samples:\", len(df))\n",
    "print(df[\"attack\"].value_counts())\n",
    "print(df[\"attack\"].value_counts(normalize=True))  # ë¹„ìœ¨ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_DIR = \"/content/TinyML\"\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# Default entry point: Flower federated simulation\n",
    "# Edit the command below if you want to run a different training script.\n",
    "print(\"Running python -m src.federated.client --save-model src/models/global_model.h5\")\n",
    "!python -m src.federated.client --save-model src/models/global_model.h5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Save trained model(s) to Google Drive\n",
    "\n",
    "This will look for common output filenames (e.g. `tiny_model.tflite`) in the project root and copy them to your Drive.\n",
    "Edit `OUTPUT_FILES` if your script uses different names or locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from google.colab import drive\n",
    "\n",
    "PROJECT_DIR = \"/content/TinyML\"\n",
    "OUTPUT_FILES = [\n",
    "    \"src/models/global_model.h5\",\n",
    "    \"src/models/global_model.tflite\",\n",
    "    \"models/global_model.h5\",\n",
    "    \"models/global_model.tflite\",\n",
    "    \"tiny_model.tflite\",\n",
    "    \"model.tflite\",\n",
    "    \"model.h5\",\n",
    "    \"saved_model.pb\"\n",
    "]\n",
    "\n",
    "# Mount Drive to store the trained models\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "dest_dir = \"/content/drive/MyDrive/TinyML_models\"\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "found_any = False\n",
    "for fname in OUTPUT_FILES:\n",
    "    src_path = os.path.join(PROJECT_DIR, fname)\n",
    "    if os.path.exists(src_path):\n",
    "        dst_path = os.path.join(dest_dir, fname)\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "        print(f\"Copied {src_path} -> {dst_path}\")\n",
    "        found_any = True\n",
    "\n",
    "if not found_any:\n",
    "    print(\"No known model files found. Make sure your training script saves a model and update OUTPUT_FILES if needed.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
